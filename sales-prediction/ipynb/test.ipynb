{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d0bfde-4105-45c8-ae86-bdf02bd4b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5705d6-1fd2-4414-8dc9-e9db7e5d060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>review_cnt</th>\n",
       "      <th>purchase_cnt</th>\n",
       "      <th>wish_cnt</th>\n",
       "      <th>sixMothRatio(puchase_cnt/review_cnt)</th>\n",
       "      <th>week_review_count</th>\n",
       "      <th>average_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>category2_encoded</th>\n",
       "      <th>category3_encoded</th>\n",
       "      <th>rolling_mean_purchase</th>\n",
       "      <th>rolling_std_purchase</th>\n",
       "      <th>week_num</th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4.873239</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>91.50</td>\n",
       "      <td>109.601551</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.742268</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>111.772090</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4.740741</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>167.75</td>\n",
       "      <td>108.944558</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.935016</td>\n",
       "      <td>3.546049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.853933</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>176.60</td>\n",
       "      <td>96.401763</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>4.647232e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23211</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>88459191933</td>\n",
       "      <td>모리모토 뉴스타 M1 내야 외야 투수 올라운드 야구 글러브 우투 좌투</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23212</th>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>88459191933</td>\n",
       "      <td>모리모토 뉴스타 M1 내야 외야 투수 올라운드 야구 글러브 우투 좌투</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23213</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>88473568229</td>\n",
       "      <td>노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식</td>\n",
       "      <td>49900.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.845528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23214</th>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>88473568229</td>\n",
       "      <td>노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식</td>\n",
       "      <td>49900.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.845528</td>\n",
       "      <td>93.0</td>\n",
       "      <td>4.526882</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>415.00</td>\n",
       "      <td>575.584920</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23215</th>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>88473568229</td>\n",
       "      <td>노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식</td>\n",
       "      <td>49900.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.845528</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.551724</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>362.00</td>\n",
       "      <td>417.224160</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.935016</td>\n",
       "      <td>3.546049e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23216 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        week_date   product_id                              product_name  \\\n",
       "0      2023-09-25   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "1      2023-10-02   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "2      2023-10-09   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "3      2023-10-16   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "4      2023-10-23   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "...           ...          ...                                       ...   \n",
       "23211  2024-09-30  88459191933    모리모토 뉴스타 M1 내야 외야 투수 올라운드 야구 글러브 우투 좌투   \n",
       "23212  2024-10-07  88459191933    모리모토 뉴스타 M1 내야 외야 투수 올라운드 야구 글러브 우투 좌투   \n",
       "23213  2024-09-30  88473568229  노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식   \n",
       "23214  2024-10-07  88473568229  노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식   \n",
       "23215  2024-10-14  88473568229  노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식   \n",
       "\n",
       "         price  review_cnt  purchase_cnt  wish_cnt  \\\n",
       "0       1000.0     61440.0        3745.0    1685.0   \n",
       "1       1000.0     61440.0        3745.0    1685.0   \n",
       "2       1000.0     61440.0        3745.0    1685.0   \n",
       "3       1000.0     61440.0        3745.0    1685.0   \n",
       "4       1000.0     61440.0        3745.0    1685.0   \n",
       "...        ...         ...           ...       ...   \n",
       "23211  79000.0         8.0          52.0      25.0   \n",
       "23212  79000.0         8.0          52.0      25.0   \n",
       "23213  49900.0        70.0        1088.0     101.0   \n",
       "23214  49900.0        70.0        1088.0     101.0   \n",
       "23215  49900.0        70.0        1088.0     101.0   \n",
       "\n",
       "       sixMothRatio(puchase_cnt/review_cnt)  week_review_count  \\\n",
       "0                                  2.386871                6.0   \n",
       "1                                  2.386871               71.0   \n",
       "2                                  2.386871               97.0   \n",
       "3                                  2.386871              108.0   \n",
       "4                                  2.386871               89.0   \n",
       "...                                     ...                ...   \n",
       "23211                              5.777778                4.0   \n",
       "23212                              5.777778                5.0   \n",
       "23213                              8.845528                1.0   \n",
       "23214                              8.845528               93.0   \n",
       "23215                              8.845528               29.0   \n",
       "\n",
       "       average_review_score  ...  category2_encoded  category3_encoded  \\\n",
       "0                  4.666667  ...               68.0               99.0   \n",
       "1                  4.873239  ...               68.0               99.0   \n",
       "2                  4.742268  ...               68.0               99.0   \n",
       "3                  4.740741  ...               68.0               99.0   \n",
       "4                  4.853933  ...               68.0               99.0   \n",
       "...                     ...  ...                ...                ...   \n",
       "23211              4.750000  ...               13.0              184.0   \n",
       "23212              4.800000  ...               13.0              184.0   \n",
       "23213              3.000000  ...                5.0              202.0   \n",
       "23214              4.526882  ...                5.0              202.0   \n",
       "23215              4.551724  ...                5.0              202.0   \n",
       "\n",
       "       rolling_mean_purchase  rolling_std_purchase  week_num  month  \\\n",
       "0                      14.00              0.000000        39      9   \n",
       "1                      91.50            109.601551        40     10   \n",
       "2                     138.00            111.772090        41     10   \n",
       "3                     167.75            108.944558        42     10   \n",
       "4                     176.60             96.401763        43     10   \n",
       "...                      ...                   ...       ...    ...   \n",
       "23211                  23.00              0.000000        40      9   \n",
       "23212                  25.50              3.535534        41     10   \n",
       "23213                   8.00              0.000000        40      9   \n",
       "23214                 415.00            575.584920        41     10   \n",
       "23215                 362.00            417.224160        42     10   \n",
       "\n",
       "       month_sin     month_cos  week_sin      week_cos  \n",
       "0      -1.000000 -1.836970e-16 -1.000000 -1.836970e-16  \n",
       "1      -0.866025  5.000000e-01 -0.992709  1.205367e-01  \n",
       "2      -0.866025  5.000000e-01 -0.970942  2.393157e-01  \n",
       "3      -0.866025  5.000000e-01 -0.935016  3.546049e-01  \n",
       "4      -0.866025  5.000000e-01 -0.885456  4.647232e-01  \n",
       "...          ...           ...       ...           ...  \n",
       "23211  -1.000000 -1.836970e-16 -0.992709  1.205367e-01  \n",
       "23212  -0.866025  5.000000e-01 -0.970942  2.393157e-01  \n",
       "23213  -1.000000 -1.836970e-16 -0.992709  1.205367e-01  \n",
       "23214  -0.866025  5.000000e-01 -0.970942  2.393157e-01  \n",
       "23215  -0.866025  5.000000e-01 -0.935016  3.546049e-01  \n",
       "\n",
       "[23216 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"./fina_preprocessing_data.csv\"\n",
    "ds = pd.read_csv(data_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e286467d-aa2e-4afb-88a3-01ac145c4490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>review_cnt</th>\n",
       "      <th>purchase_cnt</th>\n",
       "      <th>wish_cnt</th>\n",
       "      <th>sixMothRatio(puchase_cnt/review_cnt)</th>\n",
       "      <th>week_review_count</th>\n",
       "      <th>average_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>category2_encoded</th>\n",
       "      <th>category3_encoded</th>\n",
       "      <th>rolling_mean_purchase</th>\n",
       "      <th>rolling_std_purchase</th>\n",
       "      <th>week_num</th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4.873239</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>91.50</td>\n",
       "      <td>109.601551</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.742268</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>138.00</td>\n",
       "      <td>111.772090</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4.740741</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>167.75</td>\n",
       "      <td>108.944558</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.935016</td>\n",
       "      <td>3.546049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>6356018199</td>\n",
       "      <td>DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>61440.0</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>2.386871</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.853933</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>176.60</td>\n",
       "      <td>96.401763</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>4.647232e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23211</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>88459191933</td>\n",
       "      <td>모리모토 뉴스타 M1 내야 외야 투수 올라운드 야구 글러브 우투 좌투</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23212</th>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>88459191933</td>\n",
       "      <td>모리모토 뉴스타 M1 내야 외야 투수 올라운드 야구 글러브 우투 좌투</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23213</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>88473568229</td>\n",
       "      <td>노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식</td>\n",
       "      <td>49900.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.845528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23214</th>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>88473568229</td>\n",
       "      <td>노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식</td>\n",
       "      <td>49900.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.845528</td>\n",
       "      <td>93.0</td>\n",
       "      <td>4.526882</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>415.00</td>\n",
       "      <td>575.584920</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23215</th>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>88473568229</td>\n",
       "      <td>노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식</td>\n",
       "      <td>49900.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.845528</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.551724</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>362.00</td>\n",
       "      <td>417.224160</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.935016</td>\n",
       "      <td>3.546049e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23216 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        week_date   product_id                              product_name  \\\n",
       "0      2023-09-25   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "1      2023-10-02   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "2      2023-10-09   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "3      2023-10-16   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "4      2023-10-23   6356018199    DIY 목재재단 나무 원목 합판 집성목 MDF 방부목 자작나무 히노끼   \n",
       "...           ...          ...                                       ...   \n",
       "23211  2024-09-30  88459191933    모리모토 뉴스타 M1 내야 외야 투수 올라운드 야구 글러브 우투 좌투   \n",
       "23212  2024-10-07  88459191933    모리모토 뉴스타 M1 내야 외야 투수 올라운드 야구 글러브 우투 좌투   \n",
       "23213  2024-09-30  88473568229  노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식   \n",
       "23214  2024-10-07  88473568229  노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식   \n",
       "23215  2024-10-14  88473568229  노다지 영양 양곰탕 750g 7팩 곱창전골 내장탕 한우사골 즉석국 간편식   \n",
       "\n",
       "         price  review_cnt  purchase_cnt  wish_cnt  \\\n",
       "0       1000.0     61440.0        3745.0    1685.0   \n",
       "1       1000.0     61440.0        3745.0    1685.0   \n",
       "2       1000.0     61440.0        3745.0    1685.0   \n",
       "3       1000.0     61440.0        3745.0    1685.0   \n",
       "4       1000.0     61440.0        3745.0    1685.0   \n",
       "...        ...         ...           ...       ...   \n",
       "23211  79000.0         8.0          52.0      25.0   \n",
       "23212  79000.0         8.0          52.0      25.0   \n",
       "23213  49900.0        70.0        1088.0     101.0   \n",
       "23214  49900.0        70.0        1088.0     101.0   \n",
       "23215  49900.0        70.0        1088.0     101.0   \n",
       "\n",
       "       sixMothRatio(puchase_cnt/review_cnt)  week_review_count  \\\n",
       "0                                  2.386871                6.0   \n",
       "1                                  2.386871               71.0   \n",
       "2                                  2.386871               97.0   \n",
       "3                                  2.386871              108.0   \n",
       "4                                  2.386871               89.0   \n",
       "...                                     ...                ...   \n",
       "23211                              5.777778                4.0   \n",
       "23212                              5.777778                5.0   \n",
       "23213                              8.845528                1.0   \n",
       "23214                              8.845528               93.0   \n",
       "23215                              8.845528               29.0   \n",
       "\n",
       "       average_review_score  ...  category2_encoded  category3_encoded  \\\n",
       "0                  4.666667  ...               68.0               99.0   \n",
       "1                  4.873239  ...               68.0               99.0   \n",
       "2                  4.742268  ...               68.0               99.0   \n",
       "3                  4.740741  ...               68.0               99.0   \n",
       "4                  4.853933  ...               68.0               99.0   \n",
       "...                     ...  ...                ...                ...   \n",
       "23211              4.750000  ...               13.0              184.0   \n",
       "23212              4.800000  ...               13.0              184.0   \n",
       "23213              3.000000  ...                5.0              202.0   \n",
       "23214              4.526882  ...                5.0              202.0   \n",
       "23215              4.551724  ...                5.0              202.0   \n",
       "\n",
       "       rolling_mean_purchase  rolling_std_purchase  week_num  month  \\\n",
       "0                      14.00              0.000000        39      9   \n",
       "1                      91.50            109.601551        40     10   \n",
       "2                     138.00            111.772090        41     10   \n",
       "3                     167.75            108.944558        42     10   \n",
       "4                     176.60             96.401763        43     10   \n",
       "...                      ...                   ...       ...    ...   \n",
       "23211                  23.00              0.000000        40      9   \n",
       "23212                  25.50              3.535534        41     10   \n",
       "23213                   8.00              0.000000        40      9   \n",
       "23214                 415.00            575.584920        41     10   \n",
       "23215                 362.00            417.224160        42     10   \n",
       "\n",
       "       month_sin     month_cos  week_sin      week_cos  \n",
       "0      -1.000000 -1.836970e-16 -1.000000 -1.836970e-16  \n",
       "1      -0.866025  5.000000e-01 -0.992709  1.205367e-01  \n",
       "2      -0.866025  5.000000e-01 -0.970942  2.393157e-01  \n",
       "3      -0.866025  5.000000e-01 -0.935016  3.546049e-01  \n",
       "4      -0.866025  5.000000e-01 -0.885456  4.647232e-01  \n",
       "...          ...           ...       ...           ...  \n",
       "23211  -1.000000 -1.836970e-16 -0.992709  1.205367e-01  \n",
       "23212  -0.866025  5.000000e-01 -0.970942  2.393157e-01  \n",
       "23213  -1.000000 -1.836970e-16 -0.992709  1.205367e-01  \n",
       "23214  -0.866025  5.000000e-01 -0.970942  2.393157e-01  \n",
       "23215  -0.866025  5.000000e-01 -0.935016  3.546049e-01  \n",
       "\n",
       "[23216 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "week_date                                object\n",
    "product_id                                int64\n",
    "category1Id                             float64\n",
    "category2Id                             float64\n",
    "category3Id                             float64\n",
    "price                                   float64\n",
    "review_cnt                              float64\n",
    "purchase_cnt                            float64\n",
    "wish_cnt                                float64\n",
    "sixMothRatio(puchase_cnt/review_cnt)    float64\n",
    "week_review_count                       float64\n",
    "average_review_score                    float64\n",
    "week_purchase_cnt                       float64\n",
    "dtype: object\n",
    "'''\n",
    "\n",
    "df_filled = ds.copy()\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf8bd91b-b6dd-4671-937d-e769c10231b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 필터링 전:\n",
      "전체 제품 수: 453\n",
      "\n",
      "시퀀스 길이 통계:\n",
      "최소 시퀀스 길이: 2\n",
      "최대 시퀀스 길이: 310\n",
      "평균 시퀀스 길이: 51.25\n",
      "\n",
      "조정된 최소 필요 데이터 길이: 9\n",
      "충분한 데이터를 가진 제품 수: 431\n",
      "포함된 제품 비율: 95.14%\n",
      "학습중\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>review_cnt</th>\n",
       "      <th>purchase_cnt</th>\n",
       "      <th>wish_cnt</th>\n",
       "      <th>sixMothRatio(puchase_cnt/review_cnt)</th>\n",
       "      <th>week_review_count</th>\n",
       "      <th>average_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean_purchase</th>\n",
       "      <th>rolling_std_purchase</th>\n",
       "      <th>week_num</th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>training_cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>10022619427</td>\n",
       "      <td>오즈보즈 어린이 초보 스케이트보드</td>\n",
       "      <td>38800.0</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.369458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>10022619427</td>\n",
       "      <td>오즈보즈 어린이 초보 스케이트보드</td>\n",
       "      <td>38800.0</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.369458</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>12.020815</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>10022619427</td>\n",
       "      <td>오즈보즈 어린이 초보 스케이트보드</td>\n",
       "      <td>38800.0</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.369458</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8.888194</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>10022619427</td>\n",
       "      <td>오즈보즈 어린이 초보 스케이트보드</td>\n",
       "      <td>38800.0</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.369458</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>8.812869</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.935016</td>\n",
       "      <td>3.546049e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-23</td>\n",
       "      <td>10022619427</td>\n",
       "      <td>오즈보즈 어린이 초보 스케이트보드</td>\n",
       "      <td>38800.0</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.369458</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9.460444</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>4.647232e-01</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23093</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>9879202686</td>\n",
       "      <td>자동차출장배터리교체 (서울/경기/인천) 차량배터리</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>6501.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1.829861</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>9.311283</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>-1.205367e-01</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23094</th>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>9879202686</td>\n",
       "      <td>자동차출장배터리교체 (서울/경기/인천) 차량배터리 델코 DF40R</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>6501.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1.829861</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4.903226</td>\n",
       "      <td>...</td>\n",
       "      <td>46.166667</td>\n",
       "      <td>10.342469</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23095</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>9879202686</td>\n",
       "      <td>자동차출장배터리교체 (서울/경기/인천) 차량배터리</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>6501.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1.829861</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>...</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>10.807405</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-0.992709</td>\n",
       "      <td>1.205367e-01</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23096</th>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>9879202686</td>\n",
       "      <td>자동차출장배터리교체 (서울/경기/인천) 차량배터리</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>6501.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1.829861</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.971429</td>\n",
       "      <td>...</td>\n",
       "      <td>52.833333</td>\n",
       "      <td>8.304617</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>2.393157e-01</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23097</th>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>9879202686</td>\n",
       "      <td>자동차출장배터리교체 (서울/경기/인천) 차량배터리 델코 DF40R</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>6501.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>1.829861</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.166667</td>\n",
       "      <td>19.062179</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.935016</td>\n",
       "      <td>3.546049e-01</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23098 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       week_date   product_id                          product_name    price  \\\n",
       "0     2023-09-25  10022619427                    오즈보즈 어린이 초보 스케이트보드  38800.0   \n",
       "1     2023-10-02  10022619427                    오즈보즈 어린이 초보 스케이트보드  38800.0   \n",
       "2     2023-10-09  10022619427                    오즈보즈 어린이 초보 스케이트보드  38800.0   \n",
       "3     2023-10-16  10022619427                    오즈보즈 어린이 초보 스케이트보드  38800.0   \n",
       "4     2023-10-23  10022619427                    오즈보즈 어린이 초보 스케이트보드  38800.0   \n",
       "...          ...          ...                                   ...      ...   \n",
       "23093 2024-09-16   9879202686           자동차출장배터리교체 (서울/경기/인천) 차량배터리  75000.0   \n",
       "23094 2024-09-23   9879202686  자동차출장배터리교체 (서울/경기/인천) 차량배터리 델코 DF40R  75000.0   \n",
       "23095 2024-09-30   9879202686           자동차출장배터리교체 (서울/경기/인천) 차량배터리  75000.0   \n",
       "23096 2024-10-07   9879202686           자동차출장배터리교체 (서울/경기/인천) 차량배터리  75000.0   \n",
       "23097 2024-10-14   9879202686  자동차출장배터리교체 (서울/경기/인천) 차량배터리 델코 DF40R  75000.0   \n",
       "\n",
       "       review_cnt  purchase_cnt  wish_cnt  \\\n",
       "0          6502.0         684.0       0.0   \n",
       "1          6502.0         684.0       0.0   \n",
       "2          6502.0         684.0       0.0   \n",
       "3          6502.0         684.0       0.0   \n",
       "4          6502.0         684.0       0.0   \n",
       "...           ...           ...       ...   \n",
       "23093      6501.0        1054.0     662.0   \n",
       "23094      6501.0        1054.0     662.0   \n",
       "23095      6501.0        1054.0     662.0   \n",
       "23096      6501.0        1054.0     662.0   \n",
       "23097      6501.0        1054.0     662.0   \n",
       "\n",
       "       sixMothRatio(puchase_cnt/review_cnt)  week_review_count  \\\n",
       "0                                  3.369458                4.0   \n",
       "1                                  3.369458                9.0   \n",
       "2                                  3.369458                8.0   \n",
       "3                                  3.369458                4.0   \n",
       "4                                  3.369458               10.0   \n",
       "...                                     ...                ...   \n",
       "23093                              1.829861               26.0   \n",
       "23094                              1.829861               31.0   \n",
       "23095                              1.829861               30.0   \n",
       "23096                              1.829861               35.0   \n",
       "23097                              1.829861                6.0   \n",
       "\n",
       "       average_review_score  ...  rolling_mean_purchase  rolling_std_purchase  \\\n",
       "0                  5.000000  ...              13.000000              0.000000   \n",
       "1                  5.000000  ...              21.500000             12.020815   \n",
       "2                  4.875000  ...              23.000000              8.888194   \n",
       "3                  4.750000  ...              20.500000              8.812869   \n",
       "4                  4.900000  ...              23.000000              9.460444   \n",
       "...                     ...  ...                    ...                   ...   \n",
       "23093              4.923077  ...              43.500000              9.311283   \n",
       "23094              4.903226  ...              46.166667             10.342469   \n",
       "23095              4.966667  ...              47.000000             10.807405   \n",
       "23096              4.971429  ...              52.833333              8.304617   \n",
       "23097              5.000000  ...              45.166667             19.062179   \n",
       "\n",
       "       week_num  month  month_sin     month_cos  week_sin      week_cos  \\\n",
       "0            39      9  -1.000000 -1.836970e-16 -1.000000 -1.836970e-16   \n",
       "1            40     10  -0.866025  5.000000e-01 -0.992709  1.205367e-01   \n",
       "2            41     10  -0.866025  5.000000e-01 -0.970942  2.393157e-01   \n",
       "3            42     10  -0.866025  5.000000e-01 -0.935016  3.546049e-01   \n",
       "4            43     10  -0.866025  5.000000e-01 -0.885456  4.647232e-01   \n",
       "...         ...    ...        ...           ...       ...           ...   \n",
       "23093        38      9  -1.000000 -1.836970e-16 -0.992709 -1.205367e-01   \n",
       "23094        39      9  -1.000000 -1.836970e-16 -1.000000 -1.836970e-16   \n",
       "23095        40      9  -1.000000 -1.836970e-16 -0.992709  1.205367e-01   \n",
       "23096        41     10  -0.866025  5.000000e-01 -0.970942  2.393157e-01   \n",
       "23097        42     10  -0.866025  5.000000e-01 -0.935016  3.546049e-01   \n",
       "\n",
       "       time_idx  training_cutoff  \n",
       "0             0               44  \n",
       "1             1               44  \n",
       "2             2               44  \n",
       "3             3               44  \n",
       "4             4               44  \n",
       "...         ...              ...  \n",
       "23093        52               45  \n",
       "23094        53               45  \n",
       "23095        54               45  \n",
       "23096        55               45  \n",
       "23097        56               45  \n",
       "\n",
       "[23098 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, QuantileLoss\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import RMSE\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "max_prediction_length = 1  # 다음 주 예측\n",
    "max_encoder_length = 24    # 과거 12주 사용 (기존 24주에서 축소)\n",
    "min_encoder_length = 8     # 최소 8주의 데이터 필요\n",
    "\n",
    "def create_timeseries(filtered_data):\n",
    "    # time_idx 재생성\n",
    "    # week_date를 datetime 형식으로 변환\n",
    "    filtered_data['week_date'] = pd.to_datetime(filtered_data['week_date'])\n",
    "    # product_id를 문자열로 변환\n",
    "    filtered_data['product_id'] = filtered_data['product_id'].astype(str)\n",
    "    # 각 product_id마다 0부터 시작하는 time_idx 생성 -> 상품 별로 시계열 예측을 진행하도록 함.\n",
    "    filtered_data = filtered_data.sort_values([\"product_id\", \"week_date\"]).reset_index(drop=True)\n",
    "    filtered_data[\"time_idx\"] = filtered_data.groupby(\"product_id\").cumcount()\n",
    "\n",
    "    # training cutoff 설정 (각 시퀀스의 80%를 훈련에 사용)\n",
    "    filtered_data[\"training_cutoff\"] = filtered_data.groupby(\"product_id\")[\"time_idx\"].transform(\n",
    "        lambda x: int(len(x) * 0.8)\n",
    "    )\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(data):\n",
    "    # 데이터 준비 단계\n",
    "    print(\"데이터 필터링 전:\")\n",
    "    print(f\"전체 제품 수: {len(data['product_id'].unique())}\")\n",
    "\n",
    "    # 시퀀스 길이 계산\n",
    "    sequence_lengths = data.groupby('product_id').size()\n",
    "    print(\"\\n시퀀스 길이 통계:\")\n",
    "    print(f\"최소 시퀀스 길이: {sequence_lengths.min()}\")\n",
    "    print(f\"최대 시퀀스 길이: {sequence_lengths.max()}\")\n",
    "    print(f\"평균 시퀀스 길이: {sequence_lengths.mean():.2f}\")\n",
    "\n",
    "    # 최소 필요 길이 설정(8주 이상의 데이터를 가지고 있을 경우에만 활용)\n",
    "    min_required_length = min_encoder_length + max_prediction_length\n",
    "    valid_products = sequence_lengths[sequence_lengths >= min_required_length].index\n",
    "\n",
    "    print(f\"\\n조정된 최소 필요 데이터 길이: {min_required_length}\")\n",
    "    print(f\"충분한 데이터를 가진 제품 수: {len(valid_products)}\")\n",
    "    print(f\"포함된 제품 비율: {(len(valid_products) / len(sequence_lengths) * 100):.2f}%\")\n",
    "\n",
    "    # 유효한 제품만 필터링\n",
    "    filtered_data = data[data['product_id'].isin(valid_products)].copy()\n",
    "  \n",
    "    prepared_data = create_timeseries(filtered_data)\n",
    "    print('학습중')\n",
    "    print(min_required_length)\n",
    "    \n",
    "    return prepared_data\n",
    "    \n",
    "\n",
    "prepare_data(df_filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fb921b-737b-4696-83f7-95971086ea2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.prepare_data(data)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656631c1-3185-4323-b02a-0add5d9104de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, QuantileLoss\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import RMSE\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 기존 파라미터 조정\n",
    "max_prediction_length = 1  # 다음 주 예측\n",
    "max_encoder_length = 24    # 과거 12주 사용 (기존 24주에서 축소)\n",
    "min_encoder_length = 8     # 최소 8주의 데이터 필요\n",
    "\n",
    "features = [ \n",
    "             'price',\n",
    "             'review_cnt',\n",
    "             'wish_cnt',\n",
    "             'sixMothRatio(puchase_cnt/review_cnt)',\n",
    "             'week_review_count',\n",
    "             'average_review_score',\n",
    "             'category1_encoded',\n",
    "             'category2_encoded',\n",
    "             'category3_encoded',\n",
    "             'rolling_mean_purchase',\n",
    "             'rolling_std_purchase',\n",
    "             'week_num',\n",
    "             'month',\n",
    "             'month_sin',\n",
    "             'month_cos',\n",
    "             'week_sin',\n",
    "             'week_cos']\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 준비 단계\n",
    "print(\"데이터 필터링 전:\")\n",
    "print(f\"전체 제품 수: {len(df_filled['product_id'].unique())}\")\n",
    "\n",
    "# 시퀀스 길이 계산\n",
    "sequence_lengths = df_filled.groupby('product_id').size()\n",
    "print(\"\\n시퀀스 길이 통계:\")\n",
    "print(f\"최소 시퀀스 길이: {sequence_lengths.min()}\")\n",
    "print(f\"최대 시퀀스 길이: {sequence_lengths.max()}\")\n",
    "print(f\"평균 시퀀스 길이: {sequence_lengths.mean():.2f}\")\n",
    "\n",
    "# 최소 필요 길이 설정\n",
    "min_required_length = min_encoder_length + max_prediction_length\n",
    "valid_products = sequence_lengths[sequence_lengths >= min_required_length].index\n",
    "\n",
    "print(f\"\\n조정된 최소 필요 데이터 길이: {min_required_length}\")\n",
    "print(f\"충분한 데이터를 가진 제품 수: {len(valid_products)}\")\n",
    "print(f\"포함된 제품 비율: {(len(valid_products) / len(sequence_lengths) * 100):.2f}%\")\n",
    "\n",
    "\n",
    "# 유효한 제품만 필터링\n",
    "df_filtered = df_filled[df_filled['product_id'].isin(valid_products)].copy()\n",
    "\n",
    "\n",
    "# time_idx 재생성\n",
    "# week_date를 datetime 형식으로 변환\n",
    "df_filtered ['week_date'] = pd.to_datetime(df_filtered ['week_date'])\n",
    "# product_id를 문자열로 변환\n",
    "df_filtered ['product_id'] = df_filtered ['product_id'].astype(str)\n",
    "# 각 product_id마다 0부터 시작하는 time_idx 생성 -> 상품 별로 시계열 예측을 진행하도록 함.\n",
    "df_filtered = df_filtered.sort_values([\"product_id\", \"week_date\"]).reset_index(drop=True)\n",
    "df_filtered[\"time_idx\"] = df_filtered.groupby(\"product_id\").cumcount()\n",
    "\n",
    "# training cutoff 설정 (각 시퀀스의 80%를 훈련에 사용)\n",
    "df_filtered[\"training_cutoff\"] = df_filtered.groupby(\"product_id\")[\"time_idx\"].transform(\n",
    "    lambda x: int(len(x) * 0.8)\n",
    ")\n",
    "\n",
    "# 모델 저장 디렉토리 생성\n",
    "save_dir = './saved_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_filename = os.path.join(save_dir, 'temporal_fusion_transformer.pt')\n",
    "\n",
    "# Training dataset 생성\n",
    "training = TimeSeriesDataSet(\n",
    "    df_filtered[lambda x: x.time_idx <= x.training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"week_purchase_cnt\",\n",
    "    group_ids=[\"product_id\"],\n",
    "    min_encoder_length=min_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"product_id\"],\n",
    "    time_varying_known_reals=[\"time_idx\"] + features,\n",
    "    time_varying_unknown_reals=[\"week_purchase_cnt\"],\n",
    "    target_normalizer=GroupNormalizer(groups=[\"product_id\"]),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# Validation dataset 생성\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training,\n",
    "    df_filtered,\n",
    "    min_prediction_idx=training.index.time.max() + 1,\n",
    "    stop_randomization=True\n",
    ")\n",
    "\n",
    "# 데이터 로더 생성\n",
    "batch_size = 128  # 배치 크기 증가\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 2, num_workers=0)\n",
    "\n",
    "\n",
    "# Early stopping 설정 조정\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=1e-4,\n",
    "    patience=10,\n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "# 모델 파라미터 조정\n",
    "# 모델 초기화\n",
    "pl.seed_everything(42)\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=32,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.2,  # 드롭아웃 증가\n",
    "    hidden_continuous_size=16,\n",
    "    loss=RMSE(),\n",
    ")\n",
    "\n",
    "# Trainer 초기화\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    devices=1,\n",
    "    accelerator='gpu',\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback, lr_monitor],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "print(\"\\n모델 학습 시작...\")\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 모델 저장\n",
    "print(f\"\\n모델을 {model_filename}에 저장 중...\")\n",
    "torch.save({\n",
    "    'model_state_dict': tft.state_dict(),\n",
    "    'dataset_parameters': {\n",
    "        'time_varying_known_reals': training.time_varying_known_reals,\n",
    "        'time_varying_unknown_reals': training.time_varying_unknown_reals,\n",
    "        'group_ids': training.group_ids,\n",
    "        'min_encoder_length': training.min_encoder_length,\n",
    "        'max_encoder_length': training.max_encoder_length,\n",
    "        'max_prediction_length': training.max_prediction_length,\n",
    "    }\n",
    "}, model_filename)\n",
    "\n",
    "print(\"모델 저장 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 검증 세트에 대한 성능 평가\n",
    "print(\"\\n검증 세트 성능 평가:\")\n",
    "validation_predictions = tft.predict(val_dataloader)\n",
    "validation_actual = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "\n",
    "# GPU 텐서를 CPU로 이동하여 계산\n",
    "val_predictions_np = validation_predictions.cpu().numpy()\n",
    "val_actual_np = validation_actual.cpu().numpy()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(val_actual_np, val_predictions_np))\n",
    "r2 = r2_score(val_actual_np, val_predictions_np)\n",
    "\n",
    "print(f\"Validation RMSE: {rmse:.2f}\")\n",
    "print(f\"Validation R²: {r2:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3cf296d-3cad-416a-b268-580b26b5b701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:1282: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 25 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__product_id': '82562973333'}, {'__group_id__product_id': '87149885404'}, {'__group_id__product_id': '87226364197'}, {'__group_id__product_id': '87817018176'}, {'__group_id__product_id': '87844396267'}, {'__group_id__product_id': '87896780670'}, {'__group_id__product_id': '87921020002'}, {'__group_id__product_id': '87937248809'}, {'__group_id__product_id': '87952389253'}, {'__group_id__product_id': '87958278370'}]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unknown category '88208430684' encountered. Set `add_nan=True` to allow unknown categories\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/encoders.py:327\u001b[0m, in \u001b[0;36mNaNLabelEncoder.transform\u001b[0;34m(self, y, return_norm, target_scale, ignore_na)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/encoders.py:327\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: '88208430684'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 223\u001b[0m\n\u001b[1;32m    220\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# 모델 인스턴스 생성 및 학습\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m tft_model \u001b[38;5;241m=\u001b[39m \u001b[43mTFTModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmax_encoder_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_prediction_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m tft_model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# 평가 및 예측\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 50\u001b[0m, in \u001b[0;36mTFTModel.__init__\u001b[0;34m(self, data_path, features, target_column, max_encoder_length, max_prediction_length, batch_size, checkpoint_dir, model_save_dir)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m TimeSeriesDataSet(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_df[\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mtime_idx \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_cutoff],\n\u001b[1;32m     37\u001b[0m     time_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     target_normalizer\u001b[38;5;241m=\u001b[39mGroupNormalizer(groups\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# validation 데이터셋 생성\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesDataSet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_randomization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# 데이터 로더 준비\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mto_dataloader(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:1155\u001b[0m, in \u001b[0;36mTimeSeriesDataSet.from_dataset\u001b[0;34m(cls, dataset, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dataset\u001b[39m(\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28mcls\u001b[39m, dataset, data: pd\u001b[38;5;241m.\u001b[39mDataFrame, stop_randomization: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, predict: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mupdate_kwargs\n\u001b[1;32m   1137\u001b[0m ):\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m    Generate dataset with different underlying data but same variable encoders and scalers, etc.\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;124;03m        TimeSeriesDataSet: new dataset\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_randomization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_randomization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mupdate_kwargs\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:1201\u001b[0m, in \u001b[0;36mTimeSeriesDataSet.from_parameters\u001b[0;34m(cls, parameters, data, stop_randomization, predict, **update_kwargs)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomize_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m parameters\u001b[38;5;241m.\u001b[39mupdate(update_kwargs)\n\u001b[0;32m-> 1201\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:477\u001b[0m, in \u001b[0;36mTimeSeriesDataSet.__init__\u001b[0;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[1;32m    474\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_ids \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_idx])\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# preprocess data\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_names:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m target \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget normalizer is separate and not in scalers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:734\u001b[0m, in \u001b[0;36mTimeSeriesDataSet._preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(group_ids_to_encode \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat_categoricals):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# targets and its lagged versions are handled separetely\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_names \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlagged_targets:\n\u001b[0;32m--> 734\u001b[0m         data[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlagged_variables\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# save special variables\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__time_idx__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__time_idx__ is a protected column and must not be present in data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:936\u001b[0m, in \u001b[0;36mTimeSeriesDataSet.transform_values\u001b[0;34m(self, name, values, data, inverse, group_id, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;66;03m# remaining categories\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat_categoricals \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_ids \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group_ids:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# reals\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreals:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/encoders.py:329\u001b[0m, in \u001b[0;36mNaNLabelEncoder.transform\u001b[0;34m(self, y, return_norm, target_scale, ignore_na)\u001b[0m\n\u001b[1;32m    327\u001b[0m             encoded \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m y]\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 329\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    330\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown category \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m encountered. Set `add_nan=True` to allow unknown categories\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m             )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    334\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encoded, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unknown category '88208430684' encountered. Set `add_nan=True` to allow unknown categories\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import RMSE\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TFTModel:\n",
    "    def __init__(self, data_path, features, target_column, max_encoder_length, max_prediction_length, batch_size, checkpoint_dir=\"./checkpoints\", model_save_dir=\"./weights\"):\n",
    "        # 데이터 로드 및 전처리\n",
    "        self.df = pd.read_csv(data_path)\n",
    "        self.features = features\n",
    "        self.target_column = target_column\n",
    "        self.max_encoder_length = max_encoder_length\n",
    "        self.max_prediction_length = max_prediction_length\n",
    "        self.batch_size = batch_size\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.model_save_dir = model_save_dir\n",
    "\n",
    "        self.df['product_id'] = self.df['product_id'].astype(str)\n",
    "        self.df['week_date'] = pd.to_datetime(self.df['week_date'])\n",
    "        self.df = self.df.sort_values(\"week_date\").reset_index(drop=True)\n",
    "        self.df[\"time_idx\"] = (self.df[\"week_date\"] - self.df[\"week_date\"].min()).dt.days // 7  # 주 단위로 인덱스 생성\n",
    "\n",
    "        # 8:2로 train과 validation 분리\n",
    "        self.train_df, self.val_df = train_test_split(self.df, test_size=0.2, shuffle=False)\n",
    "        \n",
    "        # 훈련 데이터 준비\n",
    "        self.training_cutoff = self.train_df['time_idx'].max() - max_prediction_length\n",
    "        self.training = TimeSeriesDataSet(\n",
    "            self.train_df[lambda x: x.time_idx <= self.training_cutoff],\n",
    "            time_idx=\"time_idx\",\n",
    "            target=self.target_column,\n",
    "            group_ids=[\"product_id\"],\n",
    "            min_encoder_length=max_encoder_length // 2,\n",
    "            max_encoder_length=max_encoder_length,\n",
    "            max_prediction_length=max_prediction_length,\n",
    "            static_categoricals=[\"product_id\"],\n",
    "            time_varying_known_reals=[\"time_idx\"] + features,\n",
    "            time_varying_unknown_reals=[target_column],\n",
    "            target_normalizer=GroupNormalizer(groups=[\"product_id\"]),\n",
    "        )\n",
    "\n",
    "        # validation 데이터셋 생성\n",
    "        self.validation = TimeSeriesDataSet.from_dataset(\n",
    "            self.training,\n",
    "            self.train_df,\n",
    "            predict=True,\n",
    "            stop_randomization=True\n",
    "        )\n",
    "\n",
    "        # 데이터 로더 준비\n",
    "        self.train_dataloader = self.training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "        self.val_dataloader = self.validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "        # 모델 정의\n",
    "        self.tft = TemporalFusionTransformer.from_dataset(\n",
    "            self.training,\n",
    "            learning_rate=0.03,\n",
    "            hidden_size=16,\n",
    "            attention_head_size=1,\n",
    "            dropout=0.1,\n",
    "            hidden_continuous_size=8,\n",
    "            output_size=1,  # max_prediction_length와 동일하게 설정\n",
    "            loss=RMSE(),\n",
    "        )\n",
    "\n",
    "        # Trainer 설정\n",
    "        self.trainer = pl.Trainer(\n",
    "            max_epochs=10,\n",
    "            accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "            devices=1,\n",
    "            gradient_clip_val=0.1,\n",
    "            logger=pl.loggers.TensorBoardLogger('tb_logs'),\n",
    "            callbacks=[pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)]\n",
    "        )\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        학습을 진행하는 함수\n",
    "        \"\"\"\n",
    "        # 모델 학습\n",
    "        pl.seed_everything(42)\n",
    "        self.trainer.fit(\n",
    "            model=self.tft,\n",
    "            train_dataloaders=self.train_dataloader,\n",
    "            val_dataloaders=self.val_dataloader\n",
    "        )\n",
    "\n",
    "        # 체크포인트 저장\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, \"tft_model_checkpoint.ckpt\")\n",
    "        self.trainer.save_checkpoint(checkpoint_path)\n",
    "\n",
    "        # 모델 가중치 저장\n",
    "        os.makedirs(self.model_save_dir, exist_ok=True)\n",
    "        model_save_path = os.path.join(self.model_save_dir, \"tft_model_weights.pth\")\n",
    "        torch.save(self.tft.state_dict(), model_save_path)\n",
    "\n",
    "        print(\"모델 학습 완료 및 저장.\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        validation 데이터를 사용하여 모델 성능 평가\n",
    "        \"\"\"\n",
    "        predictions = self.trainer.predict(self.tft, self.val_dataloader)\n",
    "        predictions = torch.cat([p.prediction for p in predictions]).cpu().numpy()\n",
    "\n",
    "        # 실제 값과 예측값 비교\n",
    "        actuals = torch.cat([self.tft.to_network_output(batch)[0] for batch in iter(self.val_dataloader)]).cpu().numpy()\n",
    "        \n",
    "        mse = mean_squared_error(actuals, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(actuals, predictions)\n",
    "        \n",
    "        print(f\"Validation RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def plot_predictions(self, product_ids):\n",
    "        \"\"\"\n",
    "        각 상품별 예측 결과를 실제 값과 함께 시각화\n",
    "        \"\"\"\n",
    "        predictions = self.trainer.predict(self.tft, self.val_dataloader)\n",
    "        predictions = torch.cat([p.prediction for p in predictions]).cpu().numpy()\n",
    "\n",
    "        for product_id in product_ids:\n",
    "            product_data = self.val_df[self.val_df['product_id'] == str(product_id)]\n",
    "            if len(product_data) == 0:\n",
    "                print(f\"No data found for product {product_id}\")\n",
    "                continue\n",
    "\n",
    "            product_data = product_data.sort_values(\"week_date\")\n",
    "            true_values = product_data[self.target_column].values\n",
    "\n",
    "            # 예측값 매핑\n",
    "            pred_indices = product_data.index\n",
    "            if len(pred_indices) > len(predictions):\n",
    "                pred_indices = pred_indices[-len(predictions):]\n",
    "            product_predictions = predictions[:len(pred_indices)]\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(product_data['week_date'], true_values, color='blue', label='Actual')\n",
    "            plt.plot(product_data['week_date'].iloc[-len(product_predictions):], \n",
    "                    product_predictions, color='red', label='Predicted')\n",
    "            plt.title(f\"Product {product_id}: Actual vs Predicted Values\")\n",
    "            plt.xlabel(\"Week\")\n",
    "            plt.ylabel(\"Sales\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def predict_next_week(self, product_id):\n",
    "        \"\"\"\n",
    "        특정 상품의 다음 주 판매량 예측\n",
    "        \"\"\"\n",
    "        product_data = self.df[self.df['product_id'] == str(product_id)]\n",
    "        if len(product_data) == 0:\n",
    "            print(f\"No data found for product {product_id}\")\n",
    "            return None\n",
    "\n",
    "        encoder_data = self.training.get_inference_data(\n",
    "            product_data,\n",
    "            predict_mode=True\n",
    "        )\n",
    "        \n",
    "        predictions = self.tft.predict(encoder_data)\n",
    "        next_week_prediction = predictions[0].cpu().numpy()\n",
    "\n",
    "        # 통계 계산\n",
    "        historical_stats = {\n",
    "            'mean': product_data[self.target_column].mean(),\n",
    "            'max': product_data[self.target_column].max(),\n",
    "            'min': product_data[self.target_column].min(),\n",
    "            'last': product_data[self.target_column].iloc[-1]\n",
    "        }\n",
    "\n",
    "        print(f\"\\nProduct {product_id} Statistics:\")\n",
    "        print(f\"  Historical Mean Sales: {historical_stats['mean']:.2f}\")\n",
    "        print(f\"  Historical Max Sales: {historical_stats['max']:.2f}\")\n",
    "        print(f\"  Historical Min Sales: {historical_stats['min']:.2f}\")\n",
    "        print(f\"  Last Week Sales: {historical_stats['last']:.2f}\")\n",
    "        print(f\"  Predicted Next Week Sales: {next_week_prediction[0]:.2f}\")\n",
    "\n",
    "        return next_week_prediction[0]\n",
    "\n",
    "# 사용 예시\n",
    "#if __name__ == \"__main__\":\n",
    "    # 필요한 변수 설정\n",
    "data_path = \"./fina_preprocessing_data.csv\"\n",
    "features = [ \n",
    "             'price',\n",
    "             'review_cnt',\n",
    "             'wish_cnt',\n",
    "             'sixMothRatio(puchase_cnt/review_cnt)',\n",
    "             'week_review_count',\n",
    "             'average_review_score',\n",
    "             'category1_encoded',\n",
    "             'category2_encoded',\n",
    "             'category3_encoded',\n",
    "             'rolling_mean_purchase',\n",
    "             'rolling_std_purchase',\n",
    "             'week_num',\n",
    "             'month',\n",
    "             'month_sin',\n",
    "             'month_cos',\n",
    "             'week_sin',\n",
    "             'week_cos']\n",
    "\n",
    "target_column = 'week_purchase_cnt'\n",
    "max_encoder_length = 24\n",
    "max_prediction_length = 1\n",
    "batch_size = 64\n",
    "\n",
    "# 모델 인스턴스 생성 및 학습\n",
    "tft_model = TFTModel(data_path, features, target_column, \n",
    "                    max_encoder_length, max_prediction_length, batch_size)\n",
    "tft_model.fit()\n",
    "\n",
    "# 평가 및 예측\n",
    "predictions = tft_model.evaluate()\n",
    "\n",
    "# 예시 상품들에 대한 예측 시각화\n",
    "sample_products = tft_model.df['product_id'].unique()[:3]\n",
    "print(sample_products)\n",
    "tft_model.plot_predictions(sample_products)\n",
    "\n",
    "# 특정 상품의 다음 주 예측\n",
    "tft_model.predict_next_week(sample_products[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "264b84de-5cdc-4efd-8be2-244c27607c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.5.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pytorch-lightning in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: pytorch-forecasting in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.1.1)\n",
      "Collecting pytorch-forecasting\n",
      "  Downloading pytorch_forecasting-1.2.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jenzennii/Library/Python/3.10/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-lightning) (4.66.6)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-lightning) (1.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-lightning) (23.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-lightning) (0.11.8)\n",
      "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-forecasting) (2.4.0)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-forecasting) (1.14.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-forecasting) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pytorch-forecasting) (1.5.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.10.10)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (65.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.17.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.0)\n",
      "Downloading torch-2.5.1-cp310-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.5.1-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_forecasting-1.2.0-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: torch, torchvision, torchaudio, pytorch-forecasting\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.0\n",
      "    Uninstalling torch-2.5.0:\n",
      "      Successfully uninstalled torch-2.5.0\n",
      "  Attempting uninstall: pytorch-forecasting\n",
      "    Found existing installation: pytorch-forecasting 1.1.1\n",
      "    Uninstalling pytorch-forecasting-1.1.1:\n",
      "      Successfully uninstalled pytorch-forecasting-1.1.1\n",
      "Successfully installed pytorch-forecasting-1.2.0 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch torchvision torchaudio pytorch-lightning pytorch-forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2fb0ca0-ee8c-432b-8294-1267d09d4b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/c4/2xfj413907ng2mds_4tqrm8r0000gn/T/pip-install-2fttb2s9/pytorch_357cb588e0724029ab180095aadf7dd2/setup.py\", line 15, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
      "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b9597ca-da7d-41d6-94de-060dfc3d8a7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jenzennii/Library/Python/3.10/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4cddec5-97e8-444d-b7c2-c478d60377a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: lightning, pytorch-forecasting, pytorch-lightning, sentence-transformers, torchaudio, torchmetrics, torchvision\n",
      "---\n",
      "Name: pytorch-lightning\n",
      "Version: 2.4.0\n",
      "Summary: PyTorch Lightning is the lightweight PyTorch wrapper for ML researchers. Scale your models. Write less boilerplate.\n",
      "Home-page: https://github.com/Lightning-AI/lightning\n",
      "Author: Lightning AI et al.\n",
      "Author-email: pytorch@lightning.ai\n",
      "License: Apache-2.0\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages\n",
      "Requires: fsspec, lightning-utilities, packaging, PyYAML, torch, torchmetrics, tqdm, typing-extensions\n",
      "Required-by: lightning\n",
      "---\n",
      "Name: pytorch-forecasting\n",
      "Version: 1.2.0\n",
      "Summary: Forecasting timeseries with PyTorch - dataloaders, normalizers, metrics and models\n",
      "Home-page: \n",
      "Author: Jan Beitner\n",
      "Author-email: \n",
      "License: \n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages\n",
      "Requires: lightning, numpy, pandas, scikit-learn, scipy, torch\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch pytorch-lightning pytorch-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b50385b-c17e-4903-a62c-8070f4f1ca2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2af31997-e805-43c4-94ad-6470e8435877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:1282: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 41 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__product_id': '82562973333'}, {'__group_id__product_id': '87226364197'}, {'__group_id__product_id': '87896780670'}, {'__group_id__product_id': '87896784213'}, {'__group_id__product_id': '88042074458'}, {'__group_id__product_id': '88042110947'}, {'__group_id__product_id': '88081241709'}, {'__group_id__product_id': '88098187751'}, {'__group_id__product_id': '88100622609'}, {'__group_id__product_id': '88113889505'}]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/data/timeseries.py:1282: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 418 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__product_id': '10022619427'}, {'__group_id__product_id': '10095244123'}, {'__group_id__product_id': '10129739316'}, {'__group_id__product_id': '10182440260'}, {'__group_id__product_id': '10194331314'}, {'__group_id__product_id': '10276314469'}, {'__group_id__product_id': '10316027559'}, {'__group_id__product_id': '10583217322'}, {'__group_id__product_id': '10651348891'}, {'__group_id__product_id': '10790326479'}]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/__init__.py:143: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
      "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TemporalFusionTransformer(\n",
      "  \t\"attention_head_size\":               1\n",
      "  \t\"categorical_groups\":                {}\n",
      "  \t\"causal_attention\":                  True\n",
      "  \t\"dataset_parameters\":                {'time_idx': 'time_idx', 'target': 'week_purchase_cnt', 'group_ids': ['product_id'], 'weight': None, 'max_encoder_length': 24, 'min_encoder_length': 12, 'min_prediction_idx': 0, 'min_prediction_length': 1, 'max_prediction_length': 1, 'static_categoricals': ['product_id'], 'static_reals': ['encoder_length'], 'time_varying_known_categoricals': [], 'time_varying_known_reals': ['time_idx', 'price', 'review_cnt', 'wish_cnt', 'sixMothRatio(puchase_cnt/review_cnt)', 'week_review_count', 'average_review_score', 'category1_encoded', 'category2_encoded', 'category3_encoded', 'rolling_mean_purchase', 'rolling_std_purchase', 'week_num', 'month', 'month_sin', 'month_cos', 'week_sin', 'week_cos'], 'time_varying_unknown_categoricals': [], 'time_varying_unknown_reals': ['week_purchase_cnt'], 'variable_groups': {}, 'constant_fill_strategy': {}, 'allow_missing_timesteps': False, 'lags': {}, 'add_relative_time_idx': False, 'add_target_scales': False, 'add_encoder_length': True, 'target_normalizer': GroupNormalizer(\n",
      "  \t\tmethod='standard',\n",
      "  \t\tgroups=['product_id'],\n",
      "  \t\tcenter=True,\n",
      "  \t\tscale_by_group=False,\n",
      "  \t\ttransformation=None,\n",
      "  \t\tmethod_kwargs={}\n",
      "  \t), 'categorical_encoders': {'__group_id__product_id': NaNLabelEncoder(add_nan=False, warn=True), 'product_id': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {'encoder_length': StandardScaler(), 'time_idx': StandardScaler(), 'price': StandardScaler(), 'review_cnt': StandardScaler(), 'wish_cnt': StandardScaler(), 'sixMothRatio(puchase_cnt/review_cnt)': StandardScaler(), 'week_review_count': StandardScaler(), 'average_review_score': StandardScaler(), 'category1_encoded': StandardScaler(), 'category2_encoded': StandardScaler(), 'category3_encoded': StandardScaler(), 'rolling_mean_purchase': StandardScaler(), 'rolling_std_purchase': StandardScaler(), 'week_num': StandardScaler(), 'month': StandardScaler(), 'month_sin': StandardScaler(), 'month_cos': StandardScaler(), 'week_sin': StandardScaler(), 'week_cos': StandardScaler()}, 'randomize_length': None, 'predict_mode': False}\n",
      "  \t\"dropout\":                           0.1\n",
      "  \t\"embedding_labels\":                  {'product_id': {'10022619427': 0, '10095244123': 1, '10129739316': 2, '10182440260': 3, '10194331314': 4, '10276314469': 5, '10316027559': 6, '10583217322': 7, '10651348891': 8, '10790326479': 9, '10839131148': 10, '10857366633': 11, '10990197556': 12, '11076937403': 13, '11195202991': 14, '11199076229': 15, '11218721969': 16, '11239882600': 17, '11421983102': 18, '11545229477': 19, '11598092065': 20, '11659574428': 21, '11779789592': 22, '11831091502': 23, '11913737888': 24, '11976178121': 25, '11985210471': 26, '12099494038': 27, '12261313683': 28, '12402425757': 29, '12406570359': 30, '12549294732': 31, '12664919543': 32, '12823927460': 33, '13147435734': 34, '13154622884': 35, '13381025014': 36, '13399566549': 37, '6356018199': 38, '6485255842': 39, '6617143657': 40, '6766327742': 41, '7506929597': 42, '7781174622': 43, '80027880899': 44, '80036527278': 45, '80070124325': 46, '80137720714': 47, '80150432791': 48, '80151600598': 49, '80179015780': 50, '80260009881': 51, '80437478266': 52, '80447378951': 53, '80466364794': 54, '80471449409': 55, '80538088436': 56, '80585484638': 57, '80771696270': 58, '80909194289': 59, '80916609335': 60, '80998837833': 61, '81011449761': 62, '81022718754': 63, '81029307872': 64, '81037586677': 65, '81044807932': 66, '81072587300': 67, '81076354187': 68, '81162882669': 69, '81165039187': 70, '81182199627': 71, '81251971550': 72, '81307567948': 73, '81376726447': 74, '81432917824': 75, '81432925718': 76, '81490308013': 77, '81500447696': 78, '81592586014': 79, '81683115256': 80, '81743617172': 81, '81743662525': 82, '81769963134': 83, '81817765030': 84, '81883717746': 85, '81898265092': 86, '81944633724': 87, '81950814342': 88, '81977652281': 89, '81999320307': 90, '82035499213': 91, '82048947651': 92, '82057321861': 93, '82075021040': 94, '82084083327': 95, '82094228515': 96, '82100081230': 97, '82109132933': 98, '82114593556': 99, '82116389223': 100, '82141150395': 101, '82154885060': 102, '82155387209': 103, '82161091686': 104, '82167582057': 105, '82177741646': 106, '8218195764': 107, '82182472219': 108, '82194575327': 109, '82196153989': 110, '82198829607': 111, '82201860750': 112, '82203873495': 113, '82213682976': 114, '82224112824': 115, '82224200414': 116, '82235144540': 117, '82237266787': 118, '82239755179': 119, '82243364662': 120, '82244034272': 121, '82245440734': 122, '82250264065': 123, '82256221887': 124, '82261431626': 125, '82271542438': 126, '82278485824': 127, '82280680602': 128, '82288244906': 129, '82289916004': 130, '82293068454': 131, '82298266676': 132, '82308116319': 133, '82330465832': 134, '82343766518': 135, '82355482914': 136, '82366359065': 137, '82371516080': 138, '82374636770': 139, '82375566008': 140, '82386649071': 141, '82396216124': 142, '82409708164': 143, '82413203779': 144, '82423604772': 145, '82431335523': 146, '82439360120': 147, '82442958695': 148, '82450880093': 149, '82473335098': 150, '82484077890': 151, '82492189459': 152, '82493839762': 153, '82493840170': 154, '82498044964': 155, '82506716986': 156, '82512029192': 157, '82518325576': 158, '82518358819': 159, '82554079402': 160, '82562973333': 161, '82579351820': 162, '82584169242': 163, '82612392967': 164, '82617930980': 165, '82629272072': 166, '82644613191': 167, '82658175350': 168, '82663901180': 169, '82697228937': 170, '82725368080': 171, '82731789250': 172, '82748436013': 173, '82797428689': 174, '82803508510': 175, '82839137204': 176, '82855381541': 177, '82888223999': 178, '82904703004': 179, '82909794326': 180, '82920847039': 181, '82923956263': 182, '82938287668': 183, '82964195824': 184, '82978885242': 185, '82987858627': 186, '83018697152': 187, '83021652171': 188, '83026221734': 189, '83027433275': 190, '83032577198': 191, '83046474193': 192, '83058672505': 193, '83060973890': 194, '83124441105': 195, '83145373731': 196, '83148737984': 197, '83148914744': 198, '83154350949': 199, '83165781839': 200, '83168990735': 201, '83176583239': 202, '83185458721': 203, '83195131633': 204, '83196162009': 205, '83227652369': 206, '83242599500': 207, '83265103095': 208, '83339174174': 209, '83342948311': 210, '83353405499': 211, '83355904195': 212, '83357689027': 213, '83379992650': 214, '83396511185': 215, '83405521509': 216, '83412461028': 217, '83423045215': 218, '83439829432': 219, '83441947093': 220, '83442851433': 221, '83450413204': 222, '83452559067': 223, '83459206628': 224, '83469823485': 225, '83496016535': 226, '83544700181': 227, '83565897543': 228, '83582241229': 229, '83586891935': 230, '83588420791': 231, '83588503201': 232, '83595717401': 233, '83715863755': 234, '83722394844': 235, '83729421264': 236, '83817222587': 237, '83835508396': 238, '83844563428': 239, '83886328887': 240, '83890388520': 241, '83892959540': 242, '83916701408': 243, '83937248946': 244, '83944786359': 245, '83945044942': 246, '83956059687': 247, '83969946618': 248, '83988837837': 249, '83989019167': 250, '84051723307': 251, '84195356355': 252, '84223183690': 253, '84240189171': 254, '84253456764': 255, '84266140607': 256, '84338752005': 257, '84345558721': 258, '84366233772': 259, '84371446205': 260, '84417974537': 261, '84482901377': 262, '84486897225': 263, '84575983577': 264, '84590609622': 265, '84593454966': 266, '84595711640': 267, '84630569977': 268, '84651414760': 269, '84684925054': 270, '84739735201': 271, '84739899624': 272, '84759655602': 273, '84773371122': 274, '84852924321': 275, '84861658923': 276, '84878420163': 277, '84878502957': 278, '84920211651': 279, '84938641455': 280, '85008754353': 281, '85022115898': 282, '85050087425': 283, '85080929940': 284, '85113603549': 285, '85141197525': 286, '85219719569': 287, '85243095782': 288, '85338623974': 289, '85394939977': 290, '85465017384': 291, '85489125061': 292, '85556153151': 293, '85577317693': 294, '85578911636': 295, '85602479174': 296, '85603598515': 297, '85622876945': 298, '85635072114': 299, '85637826843': 300, '85674849480': 301, '85676427375': 302, '85747878342': 303, '85750841326': 304, '85765526144': 305, '85786543730': 306, '85827942083': 307, '85829941612': 308, '85903271022': 309, '85946192170': 310, '8597689401': 311, '85994962324': 312, '86001457602': 313, '86003052939': 314, '86011600522': 315, '86015286906': 316, '86074262188': 317, '86080579187': 318, '86168008312': 319, '86196224969': 320, '86238161590': 321, '86238199436': 322, '86253563442': 323, '86258398286': 324, '86307626335': 325, '86316244276': 326, '86340219528': 327, '86361182801': 328, '86380103731': 329, '86512422117': 330, '86512643840': 331, '86520272366': 332, '86543062469': 333, '86552777853': 334, '86564530041': 335, '86575042896': 336, '86596962625': 337, '86615650299': 338, '86634985389': 339, '86644487746': 340, '86677200634': 341, '86695180428': 342, '86716255500': 343, '86718087741': 344, '86734323610': 345, '86744054774': 346, '86750799549': 347, '86766394229': 348, '86768411788': 349, '86779626334': 350, '8678210047': 351, '86865818817': 352, '86892789310': 353, '86931391148': 354, '86947868795': 355, '86984516623': 356, '86985198344': 357, '87002755797': 358, '87034617231': 359, '87044616207': 360, '87077078211': 361, '87134721472': 362, '87149885404': 363, '87154257622': 364, '87156542226': 365, '87171220291': 366, '87194315468': 367, '87207387394': 368, '87226364197': 369, '87233647417': 370, '87256966784': 371, '87297137510': 372, '87300027307': 373, '87354688430': 374, '87416266422': 375, '87434901086': 376, '8747453599': 377, '87477209865': 378, '87528396162': 379, '87603328228': 380, '87604505038': 381, '87612495327': 382, '87616961155': 383, '87631394749': 384, '87642859084': 385, '87647012257': 386, '87664970794': 387, '87703272849': 388, '87730178392': 389, '87730829177': 390, '87737396955': 391, '87817018176': 392, '87844396267': 393, '87896780670': 394, '87896784213': 395, '87921020002': 396, '87937248809': 397, '87952389253': 398, '87958278370': 399, '87962457602': 400, '87965476173': 401, '87988876731': 402, '87991745133': 403, '88012479244': 404, '88038712401': 405, '88042074458': 406, '88042110947': 407, '88081241709': 408, '8808295228': 409, '88098187751': 410, '88100622609': 411, '88113889505': 412, '88117899204': 413, '88119947030': 414, '88184129427': 415, '88206700121': 416, '88208430684': 417, '88218200275': 418, '88222671639': 419, '88242709418': 420, '88283419814': 421, '88284816214': 422, '88291977922': 423, '88303490649': 424, '88321577019': 425, '88334988204': 426, '88347463796': 427, '88351942304': 428, '88356536951': 429, '88378913358': 430, '88380500239': 431, '88388533454': 432, '88388649996': 433, '88388890335': 434, '88401777165': 435, '88411622436': 436, '88415191727': 437, '88415318369': 438, '88415339810': 439, '88438439266': 440, '88453896846': 441, '88459191933': 442, '88473568229': 443, '8866795532': 444, '8974847230': 445, '9061388274': 446, '9270155631': 447, '9508439307': 448, '9555749627': 449, '9645322788': 450, '9694820143': 451, '9879202686': 452}}\n",
      "  \t\"embedding_paddings\":                []\n",
      "  \t\"embedding_sizes\":                   {'product_id': (453, 49)}\n",
      "  \t\"hidden_continuous_size\":            8\n",
      "  \t\"hidden_continuous_sizes\":           {}\n",
      "  \t\"hidden_size\":                       16\n",
      "  \t\"learning_rate\":                     0.03\n",
      "  \t\"log_gradient_flow\":                 False\n",
      "  \t\"log_interval\":                      -1\n",
      "  \t\"log_val_interval\":                  -1\n",
      "  \t\"lstm_layers\":                       1\n",
      "  \t\"max_encoder_length\":                24\n",
      "  \t\"monotone_constaints\":               {}\n",
      "  \t\"optimizer\":                         adam\n",
      "  \t\"optimizer_params\":                  None\n",
      "  \t\"output_size\":                       1\n",
      "  \t\"output_transformer\":                GroupNormalizer(\n",
      "  \t\tmethod='standard',\n",
      "  \t\tgroups=['product_id'],\n",
      "  \t\tcenter=True,\n",
      "  \t\tscale_by_group=False,\n",
      "  \t\ttransformation=None,\n",
      "  \t\tmethod_kwargs={}\n",
      "  \t)\n",
      "  \t\"reduce_on_plateau_min_lr\":          1e-05\n",
      "  \t\"reduce_on_plateau_patience\":        1000\n",
      "  \t\"reduce_on_plateau_reduction\":       2.0\n",
      "  \t\"share_single_variable_networks\":    False\n",
      "  \t\"static_categoricals\":               ['product_id']\n",
      "  \t\"static_reals\":                      ['encoder_length']\n",
      "  \t\"time_varying_categoricals_decoder\": []\n",
      "  \t\"time_varying_categoricals_encoder\": []\n",
      "  \t\"time_varying_reals_decoder\":        ['time_idx', 'price', 'review_cnt', 'wish_cnt', 'sixMothRatio(puchase_cnt/review_cnt)', 'week_review_count', 'average_review_score', 'category1_encoded', 'category2_encoded', 'category3_encoded', 'rolling_mean_purchase', 'rolling_std_purchase', 'week_num', 'month', 'month_sin', 'month_cos', 'week_sin', 'week_cos']\n",
      "  \t\"time_varying_reals_encoder\":        ['time_idx', 'price', 'review_cnt', 'wish_cnt', 'sixMothRatio(puchase_cnt/review_cnt)', 'week_review_count', 'average_review_score', 'category1_encoded', 'category2_encoded', 'category3_encoded', 'rolling_mean_purchase', 'rolling_std_purchase', 'week_num', 'month', 'month_sin', 'month_cos', 'week_sin', 'week_cos', 'week_purchase_cnt']\n",
      "  \t\"weight_decay\":                      0.0\n",
      "  \t\"x_categoricals\":                    ['product_id']\n",
      "  \t\"x_reals\":                           ['encoder_length', 'time_idx', 'price', 'review_cnt', 'wish_cnt', 'sixMothRatio(puchase_cnt/review_cnt)', 'week_review_count', 'average_review_score', 'category1_encoded', 'category2_encoded', 'category3_encoded', 'rolling_mean_purchase', 'rolling_std_purchase', 'week_num', 'month', 'month_sin', 'month_cos', 'week_sin', 'week_cos', 'week_purchase_cnt']\n",
      "  (loss): RMSE()\n",
      "  (logging_metrics): ModuleList(\n",
      "    (0): SMAPE()\n",
      "    (1): MAE()\n",
      "    (2): RMSE()\n",
      "    (3): MAPE()\n",
      "  )\n",
      "  (input_embeddings): MultiEmbedding(\n",
      "    (embeddings): ModuleDict(\n",
      "      (product_id): Embedding(453, 16)\n",
      "    )\n",
      "  )\n",
      "  (prescalers): ModuleDict(\n",
      "    (encoder_length): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (price): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (review_cnt): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (wish_cnt): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (sixMothRatio(puchase_cnt/review_cnt)): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (week_review_count): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (average_review_score): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (category1_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (category2_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (category3_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (rolling_mean_purchase): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (rolling_std_purchase): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (week_num): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (month): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (month_sin): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (month_cos): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (week_sin): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (week_cos): Linear(in_features=1, out_features=8, bias=True)\n",
      "    (week_purchase_cnt): Linear(in_features=1, out_features=8, bias=True)\n",
      "  )\n",
      "  (static_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=24, out_features=2, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=2, out_features=4, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (product_id): ResampleNorm(\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (encoder_length): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (encoder_length): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (encoder_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((19,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=152, out_features=16, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (context): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=16, out_features=38, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((19,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (time_idx): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (price): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (review_cnt): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (wish_cnt): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (sixMothRatio(puchase_cnt/review_cnt)): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_review_count): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (average_review_score): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (category1_encoded): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (category2_encoded): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (category3_encoded): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rolling_mean_purchase): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rolling_std_purchase): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_num): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (month): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (month_sin): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (month_cos): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_sin): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_cos): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_purchase_cnt): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (price): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (review_cnt): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (wish_cnt): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (sixMothRatio(puchase_cnt/review_cnt)): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_review_count): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (average_review_score): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (category1_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (category2_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (category3_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (rolling_mean_purchase): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (rolling_std_purchase): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_num): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (month): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (month_sin): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (month_cos): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_sin): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_cos): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_purchase_cnt): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (decoder_variable_selection): VariableSelectionNetwork(\n",
      "    (flattened_grn): GatedResidualNetwork(\n",
      "      (resample_norm): ResampleNorm(\n",
      "        (resample): TimeDistributedInterpolation()\n",
      "        (gate): Sigmoid()\n",
      "        (norm): LayerNorm((18,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (fc1): Linear(in_features=144, out_features=16, bias=True)\n",
      "      (elu): ELU(alpha=1.0)\n",
      "      (context): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "      (gate_norm): GateAddNorm(\n",
      "        (glu): GatedLinearUnit(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (fc): Linear(in_features=16, out_features=36, bias=True)\n",
      "        )\n",
      "        (add_norm): AddNorm(\n",
      "          (norm): LayerNorm((18,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (single_variable_grns): ModuleDict(\n",
      "      (time_idx): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (price): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (review_cnt): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (wish_cnt): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (sixMothRatio(puchase_cnt/review_cnt)): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_review_count): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (average_review_score): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (category1_encoded): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (category2_encoded): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (category3_encoded): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rolling_mean_purchase): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rolling_std_purchase): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_num): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (month): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (month_sin): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (month_cos): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_sin): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (week_cos): GatedResidualNetwork(\n",
      "        (resample_norm): ResampleNorm(\n",
      "          (resample): TimeDistributedInterpolation()\n",
      "          (gate): Sigmoid()\n",
      "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (fc1): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (elu): ELU(alpha=1.0)\n",
      "        (fc2): Linear(in_features=8, out_features=8, bias=True)\n",
      "        (gate_norm): GateAddNorm(\n",
      "          (glu): GatedLinearUnit(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (fc): Linear(in_features=8, out_features=32, bias=True)\n",
      "          )\n",
      "          (add_norm): AddNorm(\n",
      "            (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (prescalers): ModuleDict(\n",
      "      (time_idx): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (price): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (review_cnt): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (wish_cnt): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (sixMothRatio(puchase_cnt/review_cnt)): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_review_count): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (average_review_score): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (category1_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (category2_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (category3_encoded): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (rolling_mean_purchase): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (rolling_std_purchase): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_num): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (month): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (month_sin): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (month_cos): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_sin): Linear(in_features=1, out_features=8, bias=True)\n",
      "      (week_cos): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (static_context_variable_selection): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_initial_hidden_lstm): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_initial_cell_lstm): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (static_context_enrichment): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lstm_encoder): LSTM(16, 16, batch_first=True)\n",
      "  (lstm_decoder): LSTM(16, 16, batch_first=True)\n",
      "  (post_lstm_gate_encoder): GatedLinearUnit(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "  )\n",
      "  (post_lstm_gate_decoder): GatedLinearUnit(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "  )\n",
      "  (post_lstm_add_norm_encoder): AddNorm(\n",
      "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (post_lstm_add_norm_decoder): AddNorm(\n",
      "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (static_enrichment): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (context): Linear(in_features=16, out_features=16, bias=False)\n",
      "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (multihead_attn): InterpretableMultiHeadAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (v_layer): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (q_layers): ModuleList(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (k_layers): ModuleList(\n",
      "      (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (attention): ScaledDotProductAttention(\n",
      "      (softmax): Softmax(dim=2)\n",
      "    )\n",
      "    (w_h): Linear(in_features=16, out_features=16, bias=False)\n",
      "  )\n",
      "  (post_attn_gate_norm): GateAddNorm(\n",
      "    (glu): GatedLinearUnit(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "    )\n",
      "    (add_norm): AddNorm(\n",
      "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pos_wise_ff): GatedResidualNetwork(\n",
      "    (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (elu): ELU(alpha=1.0)\n",
      "    (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (gate_norm): GateAddNorm(\n",
      "      (glu): GatedLinearUnit(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "      )\n",
      "      (add_norm): AddNorm(\n",
      "        (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_output_gate_norm): GateAddNorm(\n",
      "    (glu): GatedLinearUnit(\n",
      "      (fc): Linear(in_features=16, out_features=32, bias=True)\n",
      "    )\n",
      "    (add_norm): AddNorm(\n",
      "      (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `TemporalFusionTransformer`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 267\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# 모델 인스턴스 생성 및 학습\u001b[39;00m\n\u001b[1;32m    265\u001b[0m tft_model \u001b[38;5;241m=\u001b[39m TFTModel(data_path, features, target_column, \n\u001b[1;32m    266\u001b[0m                     max_encoder_length, max_prediction_length, batch_size)\n\u001b[0;32m--> 267\u001b[0m \u001b[43mtft_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# # 평가 및 예측\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# predictions = tft_model.evaluate()\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# # 특정 상품의 다음 주 예측\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# tft_model.predict_next_week(sample_products[0])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 131\u001b[0m, in \u001b[0;36mTFTModel.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m    130\u001b[0m pl\u001b[38;5;241m.\u001b[39mseed_everything(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# 체크포인트 저장\u001b[39;00m\n\u001b[1;32m    138\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    500\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m     ckpt_path: Optional[_PATH] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    505\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Runs the full optimization routine.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_unwrap_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    534\u001b[0m     _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pytorch_lightning/utilities/compile.py:111\u001b[0m, in \u001b[0;36m_maybe_unwrap_optimized\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m    110\u001b[0m _check_mixed_imports(model)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `TemporalFusionTransformer`"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import RMSE\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TFTModel:\n",
    "    def __init__(self, data_path, features, target_column, max_encoder_length, max_prediction_length, batch_size, checkpoint_dir=\"./checkpoints\", model_save_dir=\"./weights\"):\n",
    "        # 데이터 로드\n",
    "        self.df = pd.read_csv(data_path)\n",
    "\n",
    "        # 데이터 전처리\n",
    "        self.features = features\n",
    "        self.target_column = target_column\n",
    "        self.max_encoder_length = max_encoder_length\n",
    "        self.max_prediction_length = max_prediction_length\n",
    "        self.batch_size = batch_size\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.model_save_dir = model_save_dir\n",
    "\n",
    "        # product_id 처리\n",
    "        self.df['product_id'] = self.df['product_id'].astype(str)  # product_id를 문자열로 변환\n",
    "        \n",
    "        # 날짜 처리\n",
    "        self.df['week_date'] = pd.to_datetime(self.df['week_date'])\n",
    "        self.df = self.df.sort_values(\"week_date\").reset_index(drop=True)\n",
    "        self.df[\"time_idx\"] = (self.df[\"week_date\"] - self.df[\"week_date\"].min()).dt.days // 7\n",
    "\n",
    "        # 각 product_id별로 데이터를 훈련/검증 세트로 분리\n",
    "        train_list = []\n",
    "        val_list = []\n",
    "\n",
    "        for product_id, group in self.df.groupby('product_id'):\n",
    "            # group은 각 product_id에 해당하는 데이터\n",
    "            group_train, group_val = train_test_split(\n",
    "                group, \n",
    "                test_size=0.2, \n",
    "                shuffle=False  # 시계열 데이터에서는 시간 순서를 유지\n",
    "            )\n",
    "            train_list.append(group_train)\n",
    "            val_list.append(group_val)\n",
    "\n",
    "        # 훈련/검증 데이터를 병합\n",
    "        self.train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "        self.val_df = pd.concat(val_list).reset_index(drop=True)\n",
    "\n",
    "        # # 디버그: 카테고리 정보 출력\n",
    "        # print(\"Unique product_ids in training:\")\n",
    "        # print(self.train_df['product_id'].unique())\n",
    "        # print(\"\\nUnique product_ids in validation:\")\n",
    "        # print(self.val_df['product_id'].unique())\n",
    "\n",
    "        # # 전체 데이터셋의 고유 product_id\n",
    "        # all_product_ids = self.df['product_id'].unique()\n",
    "        # print(f\"\\nTotal unique product_ids: {len(all_product_ids)}\")\n",
    "        \n",
    "        # TimeSeriesDataSet 생성\n",
    "        self.training = TimeSeriesDataSet(\n",
    "            self.train_df[lambda x: x.time_idx <= self.train_df['time_idx'].max() - max_prediction_length],\n",
    "            time_idx=\"time_idx\",\n",
    "            target=self.target_column,\n",
    "            group_ids=[\"product_id\"],\n",
    "            min_encoder_length=max_encoder_length // 2,\n",
    "            max_encoder_length=max_encoder_length,\n",
    "            max_prediction_length=max_prediction_length,\n",
    "            static_categoricals=[\"product_id\"],\n",
    "            time_varying_known_reals=[\"time_idx\"] + features,\n",
    "            time_varying_unknown_reals=[target_column],\n",
    "            target_normalizer=GroupNormalizer(groups=[\"product_id\"]),\n",
    "            # add_nan=True  # 새로운 카테고리 처리\n",
    "        )\n",
    "\n",
    "        # validation 데이터셋 생성\n",
    "        self.validation = TimeSeriesDataSet.from_dataset(\n",
    "            self.training,\n",
    "            self.val_df,\n",
    "            predict=True,\n",
    "            stop_randomization=True\n",
    "        )\n",
    "\n",
    "        # 데이터 로더 준비\n",
    "        self.train_dataloader = self.training.to_dataloader(\n",
    "            train=True, \n",
    "            batch_size=batch_size, \n",
    "            num_workers=0\n",
    "        )\n",
    "        self.val_dataloader = self.validation.to_dataloader(\n",
    "            train=False, \n",
    "            batch_size=batch_size, \n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        # 모델 정의\n",
    "        self.tft = TemporalFusionTransformer.from_dataset(\n",
    "            self.training,\n",
    "            learning_rate=0.03,\n",
    "            hidden_size=16,\n",
    "            attention_head_size=1,\n",
    "            dropout=0.1,\n",
    "            hidden_continuous_size=8,\n",
    "            output_size=1,\n",
    "            loss=RMSE(),\n",
    "        )\n",
    "\n",
    "        # Trainer 설정\n",
    "        self.trainer = pl.Trainer(\n",
    "            max_epochs=10,\n",
    "            devices=1,\n",
    "            accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "            gradient_clip_val=0.1,\n",
    "            # logger=pl.loggers.TensorBoardLogger('tb_logs'),\n",
    "            # callbacks=[pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5)]\n",
    "        )\n",
    "        print(self.tft)\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        학습을 진행하는 함수\n",
    "        \"\"\"\n",
    "        # 모델 학습\n",
    "        pl.seed_everything(42)\n",
    "        self.trainer.fit(\n",
    "            model=self.tft,\n",
    "            train_dataloaders=self.train_dataloader,\n",
    "            val_dataloaders=self.val_dataloader\n",
    "        )\n",
    "\n",
    "        # 체크포인트 저장\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, \"tft_model_checkpoint.ckpt\")\n",
    "        self.trainer.save_checkpoint(checkpoint_path)\n",
    "\n",
    "        # 모델 가중치 저장\n",
    "        os.makedirs(self.model_save_dir, exist_ok=True)\n",
    "        model_save_path = os.path.join(self.model_save_dir, \"tft_model_weights.pth\")\n",
    "        torch.save(self.tft.state_dict(), model_save_path)\n",
    "\n",
    "        print(\"모델 학습 완료 및 저장.\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        validation 데이터를 사용하여 모델 성능 평가\n",
    "        \"\"\"\n",
    "        predictions = self.trainer.predict(self.tft, self.val_dataloader)\n",
    "        predictions = torch.cat([p.prediction for p in predictions]).cpu().numpy()\n",
    "\n",
    "        # 실제 값과 예측값 비교\n",
    "        actuals = torch.cat([self.tft.to_network_output(batch)[0] for batch in iter(self.val_dataloader)]).cpu().numpy()\n",
    "        \n",
    "        mse = mean_squared_error(actuals, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(actuals, predictions)\n",
    "        \n",
    "        print(f\"Validation RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def plot_predictions(self, product_ids):\n",
    "        \"\"\"\n",
    "        각 상품별 예측 결과를 실제 값과 함께 시각화\n",
    "        \"\"\"\n",
    "        predictions = self.trainer.predict(self.tft, self.val_dataloader)\n",
    "        predictions = torch.cat([p.prediction for p in predictions]).cpu().numpy()\n",
    "\n",
    "        for product_id in product_ids:\n",
    "            product_data = self.val_df[self.val_df['product_id'] == product_id]\n",
    "            if len(product_data) == 0:\n",
    "                print(f\"No data found for product {product_id}\")\n",
    "                continue\n",
    "\n",
    "            product_data = product_data.sort_values(\"week_date\")\n",
    "            true_values = product_data[self.target_column].values\n",
    "\n",
    "            # 예측값 매핑\n",
    "            pred_indices = product_data.index\n",
    "            if len(pred_indices) > len(predictions):\n",
    "                pred_indices = pred_indices[-len(predictions):]\n",
    "            product_predictions = predictions[:len(pred_indices)]\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(product_data['week_date'], true_values, color='blue', label='Actual')\n",
    "            plt.plot(product_data['week_date'].iloc[-len(product_predictions):], \n",
    "                    product_predictions, color='red', label='Predicted')\n",
    "            plt.title(f\"Product {product_id}: Actual vs Predicted Values\")\n",
    "            plt.xlabel(\"Week\")\n",
    "            plt.ylabel(\"Sales\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def predict_next_week(self, product_id):\n",
    "        \"\"\"\n",
    "        특정 상품의 다음 주 판매량 예측\n",
    "        \"\"\"\n",
    "        product_data = self.df[self.df['product_id'] == product_id]\n",
    "        if len(product_data) == 0:\n",
    "            print(f\"No data found for product {product_id}\")\n",
    "            return None\n",
    "\n",
    "        encoder_data = self.training.get_inference_data(\n",
    "            product_data,\n",
    "            predict_mode=True\n",
    "        )\n",
    "        \n",
    "        predictions = self.tft.predict(encoder_data)\n",
    "        next_week_prediction = predictions[0].cpu().numpy()\n",
    "\n",
    "        # 통계 계산\n",
    "        historical_stats = {\n",
    "            'mean': product_data[self.target_column].mean(),\n",
    "            'max': product_data[self.target_column].max(),\n",
    "            'min': product_data[self.target_column].min(),\n",
    "            'last': product_data[self.target_column].iloc[-1]\n",
    "        }\n",
    "\n",
    "        print(f\"\\nProduct {product_id} Statistics:\")\n",
    "        print(f\"  Historical Mean Sales: {historical_stats['mean']:.2f}\")\n",
    "        print(f\"  Historical Max Sales: {historical_stats['max']:.2f}\")\n",
    "        print(f\"  Historical Min Sales: {historical_stats['min']:.2f}\")\n",
    "        print(f\"  Last Week Sales: {historical_stats['last']:.2f}\")\n",
    "        print(f\"  Predicted Next Week Sales: {next_week_prediction[0]:.2f}\")\n",
    "\n",
    "        return next_week_prediction[0]\n",
    "\n",
    "# 사용 예시\n",
    "#if __name__ == \"__main__\":\n",
    "    # 필요한 변수 설정\n",
    "data_path = \"./fina_preprocessing_data.csv\"\n",
    "features = [ \n",
    "             'price',\n",
    "             'review_cnt',\n",
    "             'wish_cnt',\n",
    "             'sixMothRatio(puchase_cnt/review_cnt)',\n",
    "             'week_review_count',\n",
    "             'average_review_score',\n",
    "             'category1_encoded',\n",
    "             'category2_encoded',\n",
    "             'category3_encoded',\n",
    "             'rolling_mean_purchase',\n",
    "             'rolling_std_purchase',\n",
    "             'week_num',\n",
    "             'month',\n",
    "             'month_sin',\n",
    "             'month_cos',\n",
    "             'week_sin',\n",
    "             'week_cos']\n",
    "\n",
    "target_column = 'week_purchase_cnt'\n",
    "max_encoder_length = 24\n",
    "max_prediction_length = 1\n",
    "batch_size = 64\n",
    "\n",
    "# 모델 인스턴스 생성 및 학습\n",
    "tft_model = TFTModel(data_path, features, target_column, \n",
    "                    max_encoder_length, max_prediction_length, batch_size)\n",
    "tft_model.fit()\n",
    "\n",
    "# # 평가 및 예측\n",
    "# predictions = tft_model.evaluate()\n",
    "\n",
    "# # 예시 상품들에 대한 예측 시각화\n",
    "# sample_products = tft_model.df['product_id'].unique()[:3]\n",
    "# print(sample_products)\n",
    "# tft_model.plot_predictions(sample_products)\n",
    "\n",
    "# # 특정 상품의 다음 주 예측\n",
    "# tft_model.predict_next_week(sample_products[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f54cd-1b40-41f1-8f99-bde10a700cc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29849863-635a-4d29-af08-f5f81b5793b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique product_ids in training:\n",
    "['81182199627' '82224112824' '7781174622' '81432925718' '83439829432'\n",
    " '82855381541' '11659574428' '84366233772' '7506929597' '84759655602'\n",
    " '83715863755' '12261313683' '81432917824' '82256221887' '86168008312'\n",
    " '85946192170' '80036527278' '83018697152' '82748436013' '9061388274'\n",
    " '82035499213' '85747878342' '13381025014' '81769963134' '83586891935'\n",
    " '83496016535' '82518325576' '85219719569' '86074262188' '81883717746'\n",
    " '80150432791' '83196162009' '86543062469' '12549294732' '82512029192'\n",
    " '82343766518' '6766327742' '82245440734' '84338752005' '86520272366'\n",
    " '82697228937' '85635072114' '84266140607' '81592586014' '86564530041'\n",
    " '82473335098' '84630569977' '82155387209' '85556153151' '84417974537'\n",
    " '86011600522' '82987858627' '10990197556' '86552777853' '81490308013'\n",
    " '82374636770' '82518358819' '86316244276' '84938641455' '83396511185'\n",
    " '83452559067' '11985210471' '82442958695' '85113603549' '81743617172'\n",
    " '86596962625' '83989019167' '83058672505' '80151600598' '85489125061'\n",
    " '86744054774' '86716255500' '86734323610' '82116389223' '82094228515'\n",
    " '9694820143' '86575042896' '86001457602' '13147435734' '10194331314'\n",
    " '10129739316' '11831091502' '81162882669' '9879202686' '80179015780'\n",
    " '80437478266' '80585484638' '81011449761' '81022718754' '81376726447'\n",
    " '81307567948' '11545229477' '12099494038' '80998837833' '85243095782'\n",
    " '82431335523' '83032577198' '84482901377' '83722394844' '84575983577'\n",
    " '84590609622' '83060973890' '85577317693' '83124441105' '84651414760'\n",
    " '83148914744' '82224200414' '8866795532' '10583217322' '82375566008'\n",
    " '83916701408' '82629272072' '83969946618' '82803508510' '82554079402'\n",
    " '83835508396' '82493840170' '8747453599' '84253456764' '85622876945'\n",
    " '82909794326' '86196224969' '82493839762' '86380103731' '86253563442'\n",
    " '82109132933' '86718087741' '84920211651' '83355904195' '85338623974'\n",
    " '86768411788' '86766394229' '85022115898' '83342948311' '82194575327'\n",
    " '85080929940' '84878502957' '83450413204' '85141197525' '86677200634'\n",
    " '81898265092' '86003052939' '82167582057' '86779626334' '83469823485'\n",
    " '82161091686' '82154885060' '84878420163' '85903271022' '84852924321'\n",
    " '83353405499' '83729421264' '81165039187' '83817222587' '83844563428'\n",
    " '85676427375' '85827942083' '83886328887' '80137720714' '80070124325'\n",
    " '83459206628' '80538088436' '83595717401' '81076354187' '81072587300'\n",
    " '85750841326' '81044807932' '83588503201' '81037586677' '81029307872'\n",
    " '83588420791' '85786543730' '83582241229' '83565897543' '80916609335'\n",
    " '80909194289' '80771696270' '83544700181' '80471449409' '80466364794'\n",
    " '80447378951' '80260009881' '85765526144' '83892959540' '85465017384'\n",
    " '84861658923' '84773371122' '11779789592' '84739735201' '11913737888'\n",
    " '11976178121' '84684925054' '85394939977' '10651348891' '10790326479'\n",
    " '10839131148' '11076937403' '11199076229' '85008754353' '11218721969'\n",
    " '11421983102' '11598092065' '85050087425' '11239882600' '84595711640'\n",
    " '84240189171' '84223183690' '84195356355' '84051723307' '13399566549'\n",
    " '80027880899' '83988837837' '83956059687' '83945044942' '85637826843'\n",
    " '83944786359' '83937248946' '85603598515' '84593454966' '85578911636'\n",
    " '84486897225' '85602479174' '12402425757' '12406570359' '84371446205'\n",
    " '84345558721' '12664919543' '12823927460' '83442851433' '82261431626'\n",
    " '82250264065' '82244034272' '82243364662' '82271542438' '82239755179'\n",
    " '82235144540' '82213682976' '86634985389' '82203873495' '82201860750'\n",
    " '82198829607' '82237266787' '82278485824' '82280680602' '82413203779'\n",
    " '82409708164' '82396216124' '86512643840' '82386649071' '82371516080'\n",
    " '82355482914' '82308116319' '82298266676' '82293068454' '82289916004'\n",
    " '82288244906' '82196153989' '82182472219' '81944633724' '86750799549'\n",
    " '81251971550' '81817765030' '81743662525' '81683115256' '81500447696'\n",
    " '81950814342' '82423604772' '81977652281' '82177741646' '86695180428'\n",
    " '82141150395' '82114593556' '82100081230' '82084083327' '82075021040'\n",
    " '82057321861' '82048947651' '83441947093' '86512422117' '82439360120'\n",
    " '83165781839' '83154350949' '83148737984' '83145373731' '86015286906'\n",
    " '83168990735' '83046474193' '83027433275' '83026221734' '86080579187'\n",
    " '83176583239' '83185458721' '83423045215' '83412461028' '83405521509'\n",
    " '83379992650' '83357689027' '85994962324' '83339174174' '83265103095'\n",
    " '83242599500' '83227652369' '83195131633' '82978885242' '82964195824'\n",
    " '82938287668' '82584169242' '86307626335' '82579351820' '82506716986'\n",
    " '82498044964' '86361182801' '82492189459' '82484077890' '82450880093'\n",
    " '82612392967' '86258398286' '82644613191' '82923956263' '82920847039'\n",
    " '82904703004' '82888223999' '86238161590' '82839137204' '82797428689'\n",
    " '86238199436' '82731789250' '82725368080' '82663901180' '82658175350'\n",
    " '10316027559' '6356018199' '9645322788' '10095244123' '8808295228'\n",
    " '10022619427' '9508439307' '10276314469' '8597689401' '8974847230'\n",
    " '8678210047' '10182440260' '8218195764' '6617143657' '6485255842'\n",
    " '9555749627' '86865818817' '86892789310' '86340219528' '82617930980'\n",
    " '86947868795' '86615650299' '11195202991' '86931391148' '86985198344'\n",
    " '87034617231' '87002755797' '85674849480' '87077078211' '87134721472'\n",
    " '13154622884' '87154257622' '87156542226' '87171220291' '87207387394'\n",
    " '87044616207' '83021652171' '87194315468' '87256966784' '87297137510'\n",
    " '87300027307' '87354688430' '87416266422' '87434901086' '87233647417'\n",
    " '84739899624' '86984516623' '87477209865' '82366359065' '10857366633'\n",
    " '82330465832' '87612495327' '87631394749' '87616961155' '87642859084'\n",
    " '81999320307' '9270155631' '87604505038' '85829941612' '87647012257'\n",
    " '87603328228' '87528396162' '87664970794' '87703272849' '87730178392'\n",
    " '83890388520' '86644487746' '87737396955' '87730829177' '87958278370'\n",
    " '87937248809' '87965476173' '87149885404' '87844396267' '87962457602'\n",
    " '87952389253' '87921020002' '88012479244' '87991745133' '87896780670'\n",
    " '87817018176' '87988876731' '88038712401' '88081241709' '82562973333'\n",
    " '88098187751' '88113889505' '88042110947' '88042074458' '87226364197'\n",
    " '88117899204' '88119947030' '88218200275' '88100622609' '88208430684']\n",
    "\n",
    "Unique product_ids in validation:\n",
    "['82439360120' '82100081230' '82562973333' '83227652369' '86307626335'\n",
    " '87730829177' '84938641455' '83412461028' '85022115898' '80771696270'\n",
    " '86677200634' '13147435734' '6356018199' '83423045215' '82923956263'\n",
    " '85008754353' '81376726447' '83242599500' '82167582057' '82484077890'\n",
    " '12823927460' '85338623974' '80916609335' '85827942083' '87603328228'\n",
    " '81432917824' '80036527278' '87965476173' '82109132933' '83439829432'\n",
    " '82518358819' '82473335098' '12664919543' '82177741646' '87154257622'\n",
    " '86984516623' '83441947093' '6766327742' '82386649071' '82584169242'\n",
    " '83937248946' '84482901377' '82239755179' '87233647417' '10990197556'\n",
    " '8597689401' '7781174622' '83027433275' '83944786359' '82035499213'\n",
    " '82644613191' '82293068454' '84417974537' '81883717746' '86238161590'\n",
    " '86543062469' '88119947030' '83145373731' '80466364794' '85635072114'\n",
    " '84371446205' '83945044942' '82658175350' '85578911636' '82289916004'\n",
    " '86575042896' '11545229477' '82243364662' '83032577198' '87958278370'\n",
    " '86931391148' '83956059687' '82298266676' '11598092065' '87226364197'\n",
    " '87844396267' '86520272366' '10839131148' '86985198344' '83890388520'\n",
    " '82629272072' '86750799549' '82748436013' '84575983577' '81769963134'\n",
    " '83148914744' '83892959540' '82235144540' '10857366633' '82330465832'\n",
    " '83026221734' '11659574428' '82048947651' '80179015780' '83588420791'\n",
    " '85637826843' '82308116319' '82237266787' '8678210047' '81817765030'\n",
    " '86892789310' '84486897225' '83916701408' '83148737984' '85577317693'\n",
    " '84590609622' '80260009881' '87616961155' '84051723307' '85602479174'\n",
    " '11239882600' '83060973890' '11195202991' '84195356355' '82250264065'\n",
    " '82725368080' '81950814342' '82271542438' '87703272849' '84266140607'\n",
    " '81029307872' '11218721969' '86734323610' '86564530041' '11199076229'\n",
    " '83046474193' '82261431626' '85603598515' '84223183690' '83058672505'\n",
    " '84253456764' '82697228937' '87297137510' '88038712401' '81977652281'\n",
    " '80437478266' '82256221887' '84240189171' '9694820143' '81898265092'\n",
    " '86015286906' '86238199436' '83124441105' '87952389253' '82731789250'\n",
    " '83969946618' '8866795532' '82288244906' '84366233772' '86011600522'\n",
    " '11421983102' '82244034272' '83988837837' '81037586677' '87300027307'\n",
    " '82280680602' '82278485824' '80447378951' '81999320307' '87256966784'\n",
    " '84345558721' '82663901180' '86744054774' '11076937403' '85622876945'\n",
    " '81022718754' '83989019167' '82245440734' '86552777853' '9555749627'\n",
    " '84338752005' '81944633724' '88184129427' '86596962625' '87354688430'\n",
    " '83342948311' '9879202686' '86168008312' '82075021040' '82375566008'\n",
    " '87962457602' '83595717401' '82371516080' '82224112824' '87817018176'\n",
    " '87434901086' '87937248809' '86615650299' '81072587300' '84595711640'\n",
    " '83817222587' '87034617231' '85556153151' '84651414760' '85489125061'\n",
    " '11831091502' '11985210471' '88242709418' '81683115256' '82797428689'\n",
    " '81076354187' '85676427375' '11976178121' '82374636770' '83018697152'\n",
    " '82213682976' '83168990735' '87194315468' '8808295228' '88113889505'\n",
    " '81743617172' '10651348891' '88100622609' '82612392967' '9061388274'\n",
    " '83729421264' '81011449761' '83715863755' '86512643840' '84630569977'\n",
    " '83886328887' '10583217322' '82617930980' '11913737888' '86718087741'\n",
    " '84684925054' '83165781839' '83835508396' '81743662525' '83154350949'\n",
    " '82203873495' '82355482914' '80471449409' '11779789592' '84593454966'\n",
    " '87207387394' '86003052939' '87647012257' '82987858627' '8218195764'\n",
    " '88042074458' '8974847230' '86253563442' '86766394229' '82084083327'\n",
    " '10790326479' '81044807932' '85674849480' '82343766518' '82057321861'\n",
    " '83021652171' '80151600598' '83844563428' '83722394844' '82803508510'\n",
    " '85747878342' '86074262188' '7506929597' '87416266422' '80150432791'\n",
    " '82366359065' '83588503201' '84739735201' '82224200414' '87896780670'\n",
    " '81182199627' '80998837833' '86947868795' '82904703004' '86001457602'\n",
    " '83176583239' '82978885242' '80909194289' '80538088436' '80137720714'\n",
    " '82518325576' '87077078211' '83339174174' '87002755797' '82909794326'\n",
    " '85946192170' '87737396955' '9508439307' '80585484638' '88098187751'\n",
    " '87642859084' '86865818817' '83196162009' '80070124325' '82839137204'\n",
    " '81162882669' '85994962324' '82855381541' '82554079402' '82938287668'\n",
    " '88081241709' '82964195824' '83265103095' '86258398286' '83185458721'\n",
    " '81165039187' '82920847039' '80027880899' '86196224969' '83195131633'\n",
    " '86080579187' '82579351820' '88042110947' '87044616207' '82888223999'\n",
    " '82409708164' '87991745133' '84920211651' '10182440260' '82182472219'\n",
    " '84878502957' '86716255500' '86644487746' '85394939977' '88117899204'\n",
    " '87528396162' '82194575327' '84878420163' '10194331314' '84861658923'\n",
    " '6617143657' '86695180428' '85219719569' '10022619427' '82141150395'\n",
    " '85141197525' '82154885060' '85113603549' '82116389223' '87612495327'\n",
    " '87604505038' '82155387209' '10095244123' '85080929940' '87664970794'\n",
    " '82161091686' '85050087425' '82114593556' '10129739316' '85243095782'\n",
    " '82094228515' '86634985389' '87988876731' '88012479244' '84852924321'\n",
    " '82196153989' '84773371122' '85465017384' '87477209865' '10276314469'\n",
    " '82198829607' '84759655602' '10316027559' '84739899624' '82201860750'\n",
    " '12549294732' '87171220291' '86512422117' '86768411788' '87149885404'\n",
    " '82493839762' '83405521509' '86779626334' '83396511185' '87921020002'\n",
    " '82493840170' '87134721472' '83469823485' '6485255842' '81307567948'\n",
    " '87156542226' '83586891935' '86380103731' '83496016535' '12402425757'\n",
    " '83544700181' '82423604772' '81500447696' '82413203779' '83565897543'\n",
    " '87730178392' '85750841326' '86340219528' '81592586014' '83582241229'\n",
    " '85829941612' '82492189459' '81490308013' '82396216124' '85765526144'\n",
    " '82431335523' '12099494038' '12261313683' '82498044964' '9645322788'\n",
    " '81251971550' '87631394749' '83355904195' '88218200275' '13399566549'\n",
    " '88206700121' '81432925718' '82506716986' '83353405499' '86361182801'\n",
    " '83450413204' '85786543730' '82512029192' '82442958695' '13381025014'\n",
    " '83452559067' '83379992650' '13154622884' '85903271022' '9270155631'\n",
    " '8747453599' '83459206628' '12406570359' '88208430684' '82450880093'\n",
    " '83442851433' '83357689027' '86316244276' '88222671639' '88291977922'\n",
    " '87896784213' '88284816214' '88351942304' '88303490649' '88321577019'\n",
    " '88347463796' '88283419814' '88334988204' '88380500239' '88401777165'\n",
    " '88388649996' '88388890335' '88415339810' '88415318369' '88388533454'\n",
    " '88356536951' '88411622436' '88438439266' '88378913358' '88415191727'\n",
    " '88453896846' '88473568229' '88459191933']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69069751-c4a6-4a7b-8c4b-913ac0d758bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드 및 사용 예시\n",
    "def load_saved_model(model_path, training_dataset):\n",
    "    \"\"\"\n",
    "    저장된 모델을 로드하고 예측에 사용할 수 있도록 준비합니다.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): 저장된 모델 파일 경로\n",
    "        training_dataset (TimeSeriesDataSet): 원본 학습 데이터셋\n",
    "    \n",
    "    Returns:\n",
    "        TemporalFusionTransformer: 로드된 모델\n",
    "    \"\"\"\n",
    "    # 저장된 체크포인트 로드\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    # 모델 재초기화\n",
    "    loaded_model = TemporalFusionTransformer.from_dataset(\n",
    "        training_dataset,\n",
    "        learning_rate=0.03,\n",
    "        hidden_size=32,\n",
    "        attention_head_size=2,\n",
    "        dropout=0.2,\n",
    "        hidden_continuous_size=16,\n",
    "    )\n",
    "    \n",
    "    # 모델 가중치 로드\n",
    "    loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # 모델을 평가 모드로 설정\n",
    "    loaded_model.eval()\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "# 모델 로드 예시\n",
    "loaded_tft = load_saved_model(model_filename, training)\n",
    "\n",
    "# 로드된 모델로 예측 수행\n",
    "print(\"\\n로드된 모델로 예측 수행:\")\n",
    "loaded_predictions = loaded_tft.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8241cc-119f-42ec-b762-607a8361f0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
